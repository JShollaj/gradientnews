---
title: "AI Developments: Report #2"
meta_title: "Latest Developments"
description: "Latest developments in the field of AI (Aug 14, 2023 - Aug 21, 2023)"
date: 2023-08-20T05:00:00Z
image: "https://dzslhiqiy3lnx.cloudfront.net/post-2/post-2-main.png"
categories: ["Technology", "Data"]
author: "Johnny Shollaj"
tags: ["AI", "Machine Learning"]
draft: false
---

Another week where we noticed an exponential development in LLMs and more efforts to moderate answers.
Progress has been noted also in multimodal and recommender system development, while more AI startups are
receiving massive hype.

#### What is a liquid neural network, really?

<a href="https://techcrunch.com/2023/08/17/what-is-a-liquid-neural-network-really/">
  <img src="https://techcrunch.com/wp-content/uploads/2022/08/GettyImages-1334264837.jpg?w=1390&crop=1" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>



**Main Highlight**: Liquid neural networks, a concept developed by Ramin Hasani and researchers at MIT, offer a flexible and adaptable approach to machine learning. These networks can scale down to have fewer but richer nodes, making them more efficient and less computationally expensive. 

Applications of these systems in robotics show potential for real-world use, including using Raspberry Pi for complex reasoning, reducing the number of neurons for faster solutions, and creating more transparent decision-making processes. These networks require time series data and could help in safety-critical systems by avoiding unnecessary mistakes.

***[Read Full Article](https://techcrunch.com/2023/08/17/what-is-a-liquid-neural-network-really/)***

*Brian Heater | Tech Crunch* <br></br>
*Publication Date: August 18, 2023*

---
#### Artificial intelligence for augmentation and productivity

<a href="https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818">
  <img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/202308/Hands-e1689168802555.jpg?itok=wqJrVXg9" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>



**Main Highlight**: 
The MIT Schwarzman College of Computing has awarded seed grants to seven interdisciplinary projects focusing on AI-augmented management. Funded by Andrew W. Houston and Dropbox Inc., these projects aim to leverage artificial intelligence and human-computer interaction to enhance modern workspaces, achieving better management and higher productivity. 

The selected projects span a wide range of applications, including memory prosthetics, social scenario simulation, healthcare improvement, and democratizing programming, demonstrating the potential breadth of impact on various sectors of society and the economy.

***[Read Full Article](https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818)***

*Schwarzman College of Computing | MIT* <br></br>
*Publication Date: August 18, 2023*

---

#### Reallusion Elevates Character Animation Workflows With Two-Way Live Sync and OpenUSD Support

<a href="https://blogs.nvidia.com/blog/2023/08/16/openusd-support-for-elevated-animation-workflows/">
<img src="https://blogs.nvidia.com/wp-content/uploads/2023/08/y61-1280x720.png.webp" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>

**Main Highlight**: Reallusion has updated its iClone Omniverse Connector, enhancing character animation workflows by offering real-time previews, a bidirectional workflow with Omniverse, and improved support for OpenUSD. 

The update facilitates seamless collaboration and expands creative possibilities by including real-time synchronization of projects and enhanced import functionality. These features are designed to make work between iClone and Omniverse quicker and more efficient, and come along with additional bug fixes and improvements.

***[Read Full Article](https://blogs.nvidia.com/blog/2023/08/16/openusd-support-for-elevated-animation-workflows/)***

*DANE JOHNSTON | NVIDIA* <br></br>
*Publication Date: August 16, 2023*

---


#### OpenAI acquires Global Illumination

<a href="https://openai.com/blog/openai-acquires-global-illumination">
<img src="https://i.ytimg.com/vi/vPHEtewFm3M/maxresdefault.jpg" width="500" height="500" alt="Open AI: Generative AI Company"></img>
</a>


**Main Highlight**: OpenAI has acquired the team at Global Illumination, a company known for leveraging AI in creative tools and digital experiences. The team, who previously contributed to major companies like Instagram, Facebook, YouTube, Google, Pixar, and Riot Games, has joined OpenAI to work on core products including ChatGPT.

***[Read Full Article](https://openai.com/blog/openai-acquires-global-illumination)***

*OpenAI | Various Authors* <br></br>
*Publication Date: August 16, 2023*

---

#### Using GPT-4 for content moderation

<a href="https://openai.com/blog/using-gpt-4-for-content-moderation">
<img src="https://imageio.forbes.com/specials-images/imageserve//623c6f010ae95f107980e813/0x0.jpg?format=jpg&width=1200" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: GPT-4 is being used for content policy development and moderation, significantly speeding up the iteration on policy changes from months to hours and allowing more consistent labeling.

By understanding and interpreting rules and nuances in content policies, GPT-4 is able to adapt instantly to updates, reducing reliance on human moderators.

***[Read Full Article](https://openai.com/blog/using-gpt-4-for-content-moderation)***

*OpenAI | Various Authors* <br></br>
*Publication Date: August 16, 2023*

---
### Research Blogs

#### Autonomous visual information seeking with large language models

<a href="https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifyNe-vfM669M0AsGp7RYUoWVVyt5-AQrDA34CTde4zp5CgFzaqQqiNmnxcNz3AbvKpoBXoBywipTwYlkZkjzjIilpgLPaJvSpmMLaApLNmkGqH1GHgvzmHZ2w2S5Ku-hCubbW62wZIwuhKTn2R9S5OlrBkyF2ylkU8APoVAqaagGiRc5l3u05g6qag9mU/s16000/image4.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: Google Research has introduced "AVIS: Autonomous Visual Information Seeking with Large Language Models", a novel method that elevates the performance of large language models (LLMs) on visual information seeking tasks. 

Utilizing three types of tools - computer vision tools, web search tools, and image search tools - AVIS uses an LLM-powered planner and reasoner to extract and analyze information from various sources.

The method achieved state-of-the-art results on visual information seeking datasets, showing a significant improvement in accuracy and efficiency by incorporating human decision-making data and using a dynamic, structured approach to decision-making.

***[Read Full Article](https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html)***

*Ziniu Hu, Alireza Fathi, | Google* <br></br>
*Publication Date: August 18, 2023*

---

#### Consistent Collaborative Filtering via Tensor Decomposition

<a href="https://machinelearning.apple.com/research/consistent-collaborative-filtering-updates">
<img src="https://www.mdpi.com/applsci/applsci-09-01928/article_deploy/html/images/applsci-09-01928-g001.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: A new model called Sliced Anti-symmetric Decomposition (SAD) has been developed by Apple, for collaborative filtering in recommendation systems, based on implicit feedback. 

Unlike traditional methods that estimate latent vectors for users and items, SAD introduces an additional latent vector for each item using a novel three-way tensor view. This innovation extends user-item preferences, suggesting that users may have nonlinear mental models when evaluating items. 

The model has demonstrated efficiency in both simulated and real-world datasets, outperforming seven state-of-the-art collaborative filtering models in consistency and accuracy of personalized preferences.

***[Read Full Article](https://machinelearning.apple.com/research/consistent-collaborative-filtering-updates)***

*Shiwen Zhao, Charles Crissman, Guillermo R Sapiro | Apple* <br></br>
*Publication Date: August 16, 2023*

---

#### Which GPU(s) to Get for Deep Learning

<a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">
<img src="https://images.contentstack.io/v3/assets/blt71da4c740e00faaa/bltccee8185af86036b/62693f46f8819866142d8373/gpus.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: Tim Dettmers provides comprehensive advice and insights on selecting the best GPU for deep learning, emphasizing the importance of GPU RAM, cores, tensor cores, and caches. 

The blog post is structured to guide readers through the details of GPU functionality, including comparisons between CPU and GPU, the unique features of NVIDIA's RTX 40 Ampere series, and practical recommendations for various scenarios.

The guide also includes a Q&A section to tackle common misconceptions and address specific questions like cloud vs desktop considerations, cooling strategies, and the comparison between AMD and NVIDIA.

***[Read Full Article](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/)***

*Tim Dettmers* <br></br>
*Updated Publication Date: August 8, 2023*

---

#### Scientific discovery in the age of artificial intelligence

<a href="https://www.nature.com/articles/s41586-023-06221-2.epdf?sharing_token=VNBCL-B5z7x9yroz7VHXjtRgN0jAjWel9jnR3ZoTv0NZ6DLC7sCSFQ-fnesQT80MG5tIwXOiTkbck2M8kGB2OXNe_nMse2r__TenJJwQRyiWRVae4mZzA-YquCQg9JAzwBK1UiBZQkjUqHME4HBPT-c4BOt-he7EpCkSUxM_2xo%3D">
<img src="https://www.gratasoftware.com/wp-content/uploads/2019/07/ai-analysis.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**: The integration of AI into scientific discovery has led to breakthroughs such as self-supervised learning and geometric deep learning, augmenting traditional research methods. 

These advancements enable the creation of new designs and help scientists throughout the research process, although challenges remain in data quality and the understanding of AI's capabilities and limitations. 


***[Read Full Paper](https://www.nature.com/articles/s41586-023-06221-2.epdf?sharing_token=VNBCL-B5z7x9yroz7VHXjtRgN0jAjWel9jnR3ZoTv0NZ6DLC7sCSFQ-fnesQT80MG5tIwXOiTkbck2M8kGB2OXNe_nMse2r__TenJJwQRyiWRVae4mZzA-YquCQg9JAzwBK1UiBZQkjUqHME4HBPT-c4BOt-he7EpCkSUxM_2xo%3D)***

*Wang, Fu, Du, Huang, Deac, Gao, Liu, Bengio, et.al* <br></br>
*Publication Date: August 2, 2023*

---

### Research Papers


#### Scaling Laws for Generative Mixed-Modal Language Models

<a href="https://arxiv.org/pdf/2301.03728.pdf">
<img src="https://media.arxiv-vanity.com/render-output/7160109/x17.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**: The study was conducted to explore the scaling properties of mixed-modal generative language models, examining the interaction between different modalities like text, speech, images, and code.

The research, including over 250 experiments with seven modalities and varying model sizes, has identified new mixed-modal scaling laws that capture both individual modalities and their interactions, predicting competition and synergy.

The findings provide insights into the design and training of mixed-modal models, including guidelines for hyperparameter selection, and will likely advance the development of unified models handling multiple modalities simultaneously.


***[Read Full Paper](https://arxiv.org/pdf/2301.03728.pdf)***

*Aghajanyan, Yu, Conneau, Hsu* <br></br>
*Publication Date: 10 Jan , 2023*

---

#### Sigmoid Loss for Language Image Pre-Training

<a href="https://arxiv.org/pdf/2303.15343.pdf">
<img src="https://www.researchgate.net/publication/369556647/figure/fig1/AS:11431281130904544@1679973129344/SigLiT-ImageNet-0-shot-transfer-results-with-different-training-durations-Large-batch_Q320.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**:This new sigmoid loss method performs better, particularly at smaller batch sizes, and allows for further scaling up of the batch size, without requiring additional resources. With this method, the researchers were able to achieve up to 84.5% ImageNet zero-shot accuracy within two days, making it a promising advancement for image-text pre-training.


***[Read Full Paper](https://arxiv.org/pdf/2303.15343.pdf)***

*Zhai, Mustafa, Kolesnikov, Beyer* <br></br>
*Publication Date: 4 May , 2023*

---

#### “Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models

<a href="https://arxiv.org/pdf/2308.03825.pdf">
<img src="https://www.scmagazine.com/_next/image?url=https%3A%2F%2Ffiles.scmagazine.com%2Fwp-content%2Fuploads%2F2023%2F07%2FScreenshot-2023-07-28-at-12.21.15-PM.png&w=1920&q=75" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**:The paper focuses on the misuse of Large Language Models (LLMs) and the emergence of "jailbreak prompts," which are crafted to bypass safeguards and elicit harmful content from LLMs. 

Through an extensive study of 6,387 prompts, it identifies characteristics and major attack strategies of jailbreak prompts, such as prompt injection and privilege escalation. The paper also highlights that current LLMs and safeguards are not adequately defending against these threats, with some jailbreak prompts achieving a 0.99 attack success rate on models like ChatGPT and GPT-4, and stresses the need for stronger defense mechanisms.


***[Read Full Paper](https://arxiv.org/pdf/2308.03825.pdf)***

*Shen, Chen, Backes, Zhang* <br></br>
*Publication Date: 7 Aug , 2023*

---

#### Platypus: Quick, Cheap, and Powerful Refinement of LLMs

<a href="https://arxiv.org/pdf/2308.07317v1.pdf">
<img src="https://raw.githubusercontent.com/arielnlee/Platypus/master/assets/Best_Platty.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:Platypus, a family of fine-tuned and merged Large Language Models (LLMs), has achieved the strongest performance and tops HuggingFace's Open LLM Leaderboard. 

The project introduces Open-Platypus, a curated dataset released to the public, and describes the process of fine-tuning and merging LoRA modules to bring specific domain knowledge to the forefront. 

The 13B Platypus model can be trained on a single A100 GPU in 5 hours with 25k questions, offering strong performance with significantly less data and compute resources than other state-of-the-art LLMs, opening opportunities for more improvements in the field.


***[Read Full Paper](https://arxiv.org/pdf/2308.07317v1.pdf)***

*Lee, Hunter, Ruiz* <br></br>
*Publication Date: 14 Aug , 2023*

---

#### TeCH: Text-guided Reconstruction of Lifelike Clothed Humans

<a href="https://arxiv.org/pdf/2308.08545.pdf">
<img src="https://i.ytimg.com/vi/MNA38AC9U5g/sddefault.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:TeCH has introduced a new method for reconstructing 3D clothed human figures from a single image, addressing the unsolved challenge of accurately restoring "unseen regions" of the body. The method leverages descriptive text prompts and a personalized Text-to-Image diffusion model to optimize the 3D human's geometry and texture. 

The technology shows promise for various applications in augmented and virtual reality, gaming, and more, but also raises concerns regarding potential misuse for deep-fake avatars and intellectual property issues.


***[Read Full Paper](https://arxiv.org/pdf/2308.08545.pdf)***

*Huang, Yi, Xiu et.al* <br></br>
*Publication Date: 16 Aug , 2023*

---

#### XSTEST: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models

<a href="https://arxiv.org/pdf/2308.01263.pdf">
<img src="https://media.licdn.com/dms/image/D4D22AQHL9eIg5TEFvg/feedshare-shrink_2048_1536/0/1691223790525?e=2147483647&v=beta&t=Wtr3y3gcczS4gGqiF7NjuqwumAXMUZWdxbxDVszwm1M" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:This paper introduces a test suite called XSTEST to identify exaggerated safety behaviors in large language models (LLMs), such as refusing safe requests due to misinterpretation as unsafe. 

Using XSTEST, the authors found that the Llama2 model exhibits substantial exaggerated safety behavior, refusin1g 38% of test prompts and partially refusing another 22%. 

The findings suggest that this behavior is a result of lexical overfitting, making models overly sensitive to certain words, and that OpenAI's GPT-4 is better calibrated in comparison.


***[Read Full Paper](https://arxiv.org/pdf/2308.01263.pdf)***

*Röttger, Kirk, Vidgen, Attanasio, Bianchi et.al* <br></br>
*Publication Date: 2 Aug , 2023*

---
### Development

#### Llama-GPT


<a href="https://github.com/getumbrel/llama-gpt">
<img src="https://camo.githubusercontent.com/8158198b3f4316b97d9a6d13256ad720aabc7c30e55538a7260f5deebd2a2a8b/68747470733a2f2f617070732e756d6272656c2e636f6d2f6170702f6c6c616d612d6770742f62616467652d6c696768742e737667" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:A self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device.


***[Repository](https://github.com/getumbrel/llama-gpt)***

*Author: GetUmbrel* <br></br>

---

#### Danswer


<a href="https://github.com/danswer-ai/danswer">
<img src="https://raw.githubusercontent.com/danswer-ai/danswer/1fabd9372d66cd54238847197c33f091a724803b/DanswerWithName.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: Danswer allows you to ask natural language questions against internal documents and get back reliable answers backed by quotes and references from the source material so that you can always trust what you get back. You can connect to a number of common tools such as Slack, GitHub, Confluence, amongst others.


***[Repository](https://github.com/danswer-ai/danswer)***

*Author: Danswer-AI* <br></br>

---
#### CoDeF: Content Deformation Fields for Temporally Consistent Video Processing


<a href="https://github.com/qiuyu96/CoDeF">
<img src="https://github.com/qiuyu96/CoDeF/raw/main/docs/teaser.gif" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: This repo introduces the content deformation field CoDeF, a new video representation comprising a canonical content field for static content and a temporal deformation field for transformations along time. 

The CoDeF system has been designed to lift image algorithms for video processing, enabling image-to-image translation to be adapted for video-to-video translation and keypoint detection for keypoint tracking without training. This approach provides superior cross-frame consistency in processed videos and can track non-rigid objects like water and smog.


***[Repository](https://github.com/qiuyu96/CoDeF)***

*Author: Ouyang, Wang, Xiao, Bai, Zhang, Zhou et.al* <br></br>

---

### Practical Tutorials and Resources

<br></br>

[CS324 - Large Language Models](https://stanford-cs324.github.io/winter2022/lectures/) 

Stanford Course on LLMs - Notes are open-sourced in the given links

***Liang, Hashimoto, Re, Bommasani, Xie | Stanford*** <br></br>

---

[Large Language Models: Foundation Models from the Ground Up](https://learning.edx.org/course/course-v1:Databricks+LLM102x+2T2023/home)

Databricks course available on EDX, starting from ground up to the main elements of Generative AI. Complementary for the LLM specialty certification.

***Zaharia, Raymond, Eng | Databricks*** <br></br>

---

[LangChain: Various Tutorials](https://blog.langchain.dev/)

Various tutorials which integrate LangChain with specific tools or frameworks, such as Predibase, Zep or Qdrant

***LangChain et. al*** <br></br>

---

[DeepLearning AI: Large Language Models with Semantic Search](https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/)

Free tutorial teaching concepts like dense retrieval, which elevates the relevance of retrieved information, leading to improved search results beyond traditional keyword search, and reranking, which injects the intelligence of LLMs into asearch system, making it faster and more effective.  

***Cohere x DeepLearning*** <br></br>

---

[DeepLearning AI: Evaluating and Debugging Generative AI](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)

Free tutorial teaching concepts like monitoring and tracing of LLMs over time in complex interactions and properly debugging by use case.

***W&B x DeepLearning*** <br></br>

---

[DeepLearning AI: Building Generative AI Applications with Gradio](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/)

Free tutorial teaching how to create apps which integrate easily Generative AI (Hugging Face Integrations).

***Hugging Face x DeepLearning*** <br></br>



