---
title: "AI Developments: Report #2"
meta_title: "Latest Developments"
description: "Latest developments in the field of AI (Aug 7, 2023 - Aug 14, 2023)"
date: 2023-08-20T05:00:00Z
image: "https://dzslhiqiy3lnx.cloudfront.net/post-2/post-2-main.png"
categories: ["Technology", "Data"]
author: "Johnny Shollaj"
tags: ["AI", "Machine Learning"]
draft: false
---

### General News

#### What is a liquid neural network, really?

<a href="https://techcrunch.com/2023/08/17/what-is-a-liquid-neural-network-really/">
  <img src="https://techcrunch.com/wp-content/uploads/2022/08/GettyImages-1334264837.jpg?w=1390&crop=1" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>



**Main Highlight**: Liquid neural networks, a concept developed by Ramin Hasani and researchers at MIT, offer a flexible and adaptable approach to machine learning. These networks can scale down to have fewer but richer nodes, making them more efficient and less computationally expensive. 

Applications of these systems in robotics show potential for real-world use, including using Raspberry Pi for complex reasoning, reducing the number of neurons for faster solutions, and creating more transparent decision-making processes. These networks require time series data and could help in safety-critical systems by avoiding unnecessary mistakes.

***[Read Full Article](https://techcrunch.com/2023/08/17/what-is-a-liquid-neural-network-really/)***

*Brian Heater | Tech Crunch* <br></br>
*Publication Date: August 18, 2023*

---
#### Artificial intelligence for augmentation and productivity

<a href="https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818">
  <img src="https://news.mit.edu/sites/default/files/styles/news_article__image_gallery/public/images/202308/Hands-e1689168802555.jpg?itok=wqJrVXg9" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>



**Main Highlight**: 
The MIT Schwarzman College of Computing has awarded seed grants to seven interdisciplinary projects focusing on AI-augmented management. Funded by Andrew W. Houston and Dropbox Inc., these projects aim to leverage artificial intelligence and human-computer interaction to enhance modern workspaces, achieving better management and higher productivity. 

The selected projects span a wide range of applications, including memory prosthetics, social scenario simulation, healthcare improvement, and democratizing programming, demonstrating the potential breadth of impact on various sectors of society and the economy.

***[Read Full Article](https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818)***

*Schwarzman College of Computing | MIT* <br></br>
*Publication Date: August 18, 2023*

---

#### Reallusion Elevates Character Animation Workflows With Two-Way Live Sync and OpenUSD Support

<a href="https://blogs.nvidia.com/blog/2023/08/16/openusd-support-for-elevated-animation-workflows/">
<img src="https://blogs.nvidia.com/wp-content/uploads/2023/08/y61-1280x720.png.webp" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>

**Main Highlight**: Reallusion has updated its iClone Omniverse Connector, enhancing character animation workflows by offering real-time previews, a bidirectional workflow with Omniverse, and improved support for OpenUSD. 

The update facilitates seamless collaboration and expands creative possibilities by including real-time synchronization of projects and enhanced import functionality. These features are designed to make work between iClone and Omniverse quicker and more efficient, and come along with additional bug fixes and improvements.

***[Read Full Article](https://blogs.nvidia.com/blog/2023/08/16/openusd-support-for-elevated-animation-workflows/)***

*DANE JOHNSTON | NVIDIA* <br></br>
*Publication Date: August 16, 2023*

---


#### OpenAI acquires Global Illumination

<a href="https://openai.com/blog/openai-acquires-global-illumination">
<img src="https://i.ytimg.com/vi/vPHEtewFm3M/maxresdefault.jpg" width="500" height="500" alt="Open AI: Generative AI Company"></img>
</a>


**Main Highlight**: OpenAI has acquired the team at Global Illumination, a company known for leveraging AI in creative tools and digital experiences. The team, who previously contributed to major companies like Instagram, Facebook, YouTube, Google, Pixar, and Riot Games, has joined OpenAI to work on core products including ChatGPT.

***[Read Full Article](https://openai.com/blog/openai-acquires-global-illumination)***

*OpenAI | Various Authors* <br></br>
*Publication Date: August 16, 2023*

---

#### Using GPT-4 for content moderation

<a href="https://openai.com/blog/using-gpt-4-for-content-moderation">
<img src="https://imageio.forbes.com/specials-images/imageserve//623c6f010ae95f107980e813/0x0.jpg?format=jpg&width=1200" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: GPT-4 is being used for content policy development and moderation, significantly speeding up the iteration on policy changes from months to hours and allowing more consistent labeling.

By understanding and interpreting rules and nuances in content policies, GPT-4 is able to adapt instantly to updates, reducing reliance on human moderators.

***[Read Full Article](https://openai.com/blog/using-gpt-4-for-content-moderation)***

*OpenAI | Various Authors* <br></br>
*Publication Date: August 16, 2023*

---
### Research Blogs

#### Autonomous visual information seeking with large language models

<a href="https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifyNe-vfM669M0AsGp7RYUoWVVyt5-AQrDA34CTde4zp5CgFzaqQqiNmnxcNz3AbvKpoBXoBywipTwYlkZkjzjIilpgLPaJvSpmMLaApLNmkGqH1GHgvzmHZ2w2S5Ku-hCubbW62wZIwuhKTn2R9S5OlrBkyF2ylkU8APoVAqaagGiRc5l3u05g6qag9mU/s16000/image4.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: Google Research has introduced "AVIS: Autonomous Visual Information Seeking with Large Language Models", a novel method that elevates the performance of large language models (LLMs) on visual information seeking tasks. 

Utilizing three types of tools - computer vision tools, web search tools, and image search tools - AVIS uses an LLM-powered planner and reasoner to extract and analyze information from various sources.

The method achieved state-of-the-art results on visual information seeking datasets, showing a significant improvement in accuracy and efficiency by incorporating human decision-making data and using a dynamic, structured approach to decision-making.

***[Read Full Article](https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html)***

*Ziniu Hu, Alireza Fathi, | Google* <br></br>
*Publication Date: August 18, 2023*

---

#### Consistent Collaborative Filtering via Tensor Decomposition

<a href="https://machinelearning.apple.com/research/consistent-collaborative-filtering-updates">
<img src="https://www.mdpi.com/applsci/applsci-09-01928/article_deploy/html/images/applsci-09-01928-g001.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: A new model called Sliced Anti-symmetric Decomposition (SAD) has been developed by Apple, for collaborative filtering in recommendation systems, based on implicit feedback. 

Unlike traditional methods that estimate latent vectors for users and items, SAD introduces an additional latent vector for each item using a novel three-way tensor view. This innovation extends user-item preferences, suggesting that users may have nonlinear mental models when evaluating items. 

The model has demonstrated efficiency in both simulated and real-world datasets, outperforming seven state-of-the-art collaborative filtering models in consistency and accuracy of personalized preferences.

***[Read Full Article](https://machinelearning.apple.com/research/consistent-collaborative-filtering-updates)***

*Shiwen Zhao, Charles Crissman, Guillermo R Sapiro | Apple* <br></br>
*Publication Date: August 16, 2023*

---

#### Which GPU(s) to Get for Deep Learning

<a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">
<img src="https://images.contentstack.io/v3/assets/blt71da4c740e00faaa/bltccee8185af86036b/62693f46f8819866142d8373/gpus.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: Tim Dettmers provides comprehensive advice and insights on selecting the best GPU for deep learning, emphasizing the importance of GPU RAM, cores, tensor cores, and caches. 

The blog post is structured to guide readers through the details of GPU functionality, including comparisons between CPU and GPU, the unique features of NVIDIA's RTX 40 Ampere series, and practical recommendations for various scenarios.

The guide also includes a Q&A section to tackle common misconceptions and address specific questions like cloud vs desktop considerations, cooling strategies, and the comparison between AMD and NVIDIA.

***[Read Full Article](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/)***

*Tim Dettmers* <br></br>
*Updated Publication Date: August 8, 2023*

---

#### Scientific discovery in the age of artificial intelligence

<a href="https://www.nature.com/articles/s41586-023-06221-2.epdf?sharing_token=VNBCL-B5z7x9yroz7VHXjtRgN0jAjWel9jnR3ZoTv0NZ6DLC7sCSFQ-fnesQT80MG5tIwXOiTkbck2M8kGB2OXNe_nMse2r__TenJJwQRyiWRVae4mZzA-YquCQg9JAzwBK1UiBZQkjUqHME4HBPT-c4BOt-he7EpCkSUxM_2xo%3D">
<img src="https://www.gratasoftware.com/wp-content/uploads/2019/07/ai-analysis.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**: The integration of AI into scientific discovery has led to breakthroughs such as self-supervised learning and geometric deep learning, augmenting traditional research methods. 

These advancements enable the creation of new designs and help scientists throughout the research process, although challenges remain in data quality and the understanding of AI's capabilities and limitations. 


***[Read Full Paper](https://www.nature.com/articles/s41586-023-06221-2.epdf?sharing_token=VNBCL-B5z7x9yroz7VHXjtRgN0jAjWel9jnR3ZoTv0NZ6DLC7sCSFQ-fnesQT80MG5tIwXOiTkbck2M8kGB2OXNe_nMse2r__TenJJwQRyiWRVae4mZzA-YquCQg9JAzwBK1UiBZQkjUqHME4HBPT-c4BOt-he7EpCkSUxM_2xo%3D)***

*Wang, Fu, Du, Huang, Deac, Gao, Liu, Bengio, et.al* <br></br>
*Publication Date: August 2, 2023*

---

#### Microsoft Azure: [Scale generative AI with new Azure AI infrastructure advancements and availability](https://azure.microsoft.com/en-us/blog/scale-generative-ai-with-new-azure-ai-infrastructure-advancements-and-availability/)

**Summary**:
Microsoft Azure has made critical advancements in AI infrastructure, positioning generative AI as a transformative force across multiple industries. They've announced the global expansion of Azure OpenAI Service, making GPT-4 and GPT-3.5-Turbo available in new regions. The ND H100 v5 Virtual Machine series, equipped with NVIDIA H100 GPUs, has now been released to cater to complex AI workloads. This expansion enhances Azure's offerings, enabling users to build next-generation, AI-powered applications and providing businesses with unparalleled generative AI capabilities.

**Key Takeaway**:
The latest advancements in Azure's AI infrastructure underscore the commitment to scaling AI capabilities worldwide, allowing for faster and more effective deployment of AI solutions. For businesses, this means increased efficiency, innovation, and adaptability in areas ranging from manufacturing to financial services. These enhancements align with the growing global demand for robust, scalable AI, setting the stage for a new era of innovation that can shape various industries. Leveraging Azureâ€™s expanded infrastructure can be a strategic move for businesses aiming to gain a competitive edge through AI-driven solutions.

***[Read Full Article](https://azure.microsoft.com/en-us/blog/scale-generative-ai-with-new-azure-ai-infrastructure-advancements-and-availability/)***


*Nidhi Chappell,  Eric Boyd | Azure* <br></br>
*Publication Date: August 7, 2023*

----

### Research Papers

#### [Evaluating the performance of large language models: ChatGPT and Google Bard in generating differential diagnoses in clinicopathological conferences of neurodegenerative disorders](https://onlinelibrary.wiley.com/doi/10.1111/bpa.13207)


**Summary:**
This study evaluated the use of large language models (LLMs), specifically ChatGPT-3.5, ChatGPT-4, and Google Bard, in predicting neuropathological diagnoses from clinical summaries for 25 cases of neurodegenerative disorders at the Mayo Clinic. The models' predictions were compared to the final clinical diagnoses made by physicians. The primary diagnoses were correct in 32% of cases for ChatGPT-3.5, 52% for ChatGPT-4, and 40% for Google Bard. Correct diagnoses were included among the multiple diagnoses in 76% of cases for ChatGPT-3.5, 84% for ChatGPT-4, and 76% for Google Bard

**Key Takeaway**: The results highlight the potential of LLMs like ChatGPT in neuropathology, especially in facilitating comprehensive discussions in clinicopathological conferences.

***[Read Full Paper](https://onlinelibrary.wiley.com/doi/10.1111/bpa.13207)***


*Shunsuke Koga, Nicholas B. Martin, Dennis W. Dickson* <br></br>
*Publication Date: August 8, 2023*

---

#### [Contextualized Knowledge Graph Embedding for Explainable Talent Training Course Recommendation](https://dl.acm.org/doi/pdf/10.1145/3597022)

**Summary:**
The paper introduces a novel approach called Contextualized Knowledge Graph Embedding (CKGE) for personalized employee training course recommendations. CKGE integrates both neighbor semantics and high-order connections to model individual learning motivations, using a unique KG-based Transformer (KGformer). Through relational attention, structural encoding, and path prediction, CKGE aims to provide precise and explainable recommendations. Extensive experiments on real-world datasets support the method's effectiveness and interpretability.

**Key Takeaways**:

- Innovative Approach: CKGE offers a fresh perspective on course recommendations by considering complex learning motivations.

- Explainability: The integration of knowledge graphs and special attention mechanisms ensures transparent, meaningful recommendations.

- Precision: The method promises accurate predictions for course preferences tailored to individual needs.

- Relevance: CKGE aligns with the trend of leveraging data-driven paradigms in talent management, having potential high impact in personalized learning and development within enterprises.

***[Read Full Paper](https://dl.acm.org/doi/pdf/10.1145/3597022)***


*Yang, Zhang, Song, Dong, Zhu, Li* <br></br>
*Publication Date: August 8, 2023*

---

#### [Large-scale Urban Cellular Traffic Generation via Knowledge-Enhanced GANs with Multi-Periodic Patterns](https://dl.acm.org/doi/pdf/10.1145/3580305.3599853)

**Summary:**
The paper proposes a knowledge-enhanced GAN (Generative Adversarial Network) for generating large-scale urban cellular traffic, essential for 5G network planning. This novel model simulates multi-periodic patterns and long-term aperiodic dynamics, capturing urban environmental influences through a knowledge graph (KG). Extensive experiments demonstrate a substantial performance improvement of over 32.77% compared to state-of-the-art models, with urban knowledge contributing 4.71% enhancement. Generalization and robustness across different urban areas also affirm the model's utility.

**Key Takeaways**:

- Innovative Model: The introduction of a GAN model with urban knowledge graphs allows for accurate simulation of long-term cellular traffic, capturing both periodic and aperiodic patterns.

- Urban Environment Integration: By considering various urban factors, the model effectively tailors cellular traffic predictions to specific urban dynamics.

- Significant Performance Improvement: With over 32% improvement compared to existing models and a further 4.71% from urban knowledge enhancement, the method exhibits superior fidelity.

- Generalization & Application: Demonstrated effectiveness across different urban areas and potential applicability to other traffic types such as website visiting and urban passenger traffic supports the model's broader relevance and scalability.



***[Read Full Paper](https://dl.acm.org/doi/pdf/10.1145/3580305.3599853)***


*Hui, Wang, Yang, Feng, Zhu, Deng, Hui* <br></br>
*Publication Date: August 8, 2023*

---

### Development

#### Hugging Face: [Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account](https://huggingface.co/blog/aws-marketplace)

**Summary**:
The Hugging Face Platform is now available on the AWS Marketplace, allowing AWS customers to pay for Hugging Face services directly through their AWS accounts. This integration simplifies the payment process for services like Inference Endpoints, Spaces Hardware Upgrades, and AutoTrain, facilitating easier access to popular machine learning models. The subscription process is outlined for users, ensuring seamless connectivity between AWS and Hugging Face accounts.

**Key Takeaway**:
This new integration between Hugging Face and AWS removes financial and administrative barriers, making it more convenient for businesses to adopt AI technologies. By centralizing billing through the AWS account, companies can efficiently manage payments for all Hugging Face services, fostering easier collaboration and utilization of machine learning models like Llama 2, StarCoder, or BERT. The identical pricing to public Hugging Face pricing, billed through AWS, streamlines the adoption process for developers and organizations.

***[Read Full Article](https://huggingface.co/blog/aws-marketplace)***


*Simon Brandeis, Philipp Schmid, Jeff Boudier* <br></br>
*Publication Date: August 10, 2023*

---

#### Hugging Face: [Releasing Swift Transformers: Run On-Device LLMs in Apple Devices](https://huggingface.co/blog/swift-coreml-llm)

**Summary**:
A slew of updates and tools were released today to support text generation in Swift, including the new swift-transformers package and the swift-chat app. Tools for Core ML conversion, like exporters and transformers-to-coreml, have been updated and some converted models like Llama 2 7B or Falcon 7B are ready for use. The details cover multiple aspects of conversion to Core ML, optimization techniques, tokenization, and more, including specific coding instructions.

**Key Takeaway**:
The release is a comprehensive step forward for Swift developers working with text generation and Core ML models, making the conversion and optimization process more streamlined and flexible. With support for different tokenization methods, abstraction of complex processes, and focus on optimization techniques, these updates enhance efficiency and provide a foundation for developers to work with different models and generation algorithms, offering an engaging platform for ongoing improvements and innovations.

***[Read Full Article](https://huggingface.co/blog/swift-coreml-llm)***


*Pedro Cuenca* <br></br>
*Publication Date: August 8, 2023*

---

#### Hugging Face: [Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action](https://huggingface.co/blog/deploy-deepfloydif-using-bentoml)

**Summary:**
The article details how to deploy Hugging Face models, such as the DeepFloyd IF text-to-image model, using BentoML, an open-source platform for machine learning model serving and deployment. It walks through defining, saving, and deploying the model, and outlines how to use DeepFloyd IF in BentoML. Detailed instructions for preparing the environment, scaling runners, and building a deployable Bento are provided, including specific code and command examples.

**Key Takeaway:**
BentoML offers a comprehensive solution for deploying Hugging Face models like DeepFloyd IF in a production-ready manner. The article guides users step-by-step through the process, making it accessible even for those new to the platform. The capability of BentoML to handle various ML frameworks, along with its ease of use and integration with tools like Docker and Kubernetes, makes it a powerful tool for real-world deployment and scaling of AI applications.

***[Read Full Article](https://huggingface.co/blog/deploy-deepfloydif-using-bentoml)***


*Sherlock Xu , Zhao Shenyang* <br></br>
*Publication Date: August 9, 2023*


#### GitHub: [Generative Agents: Interactive Simulacra of Human Behavior](https://github.com/joonspk-research/generative_agents)


**Summary:**
The research paper titled "Generative Agents: Interactive Simulacra of Human Behavior" has been accompanied by a repository containing a core simulation module for generative agents that simulate human behaviors. The repository includes detailed instructions for setting up the simulation environment locally, running, replaying, and demoing a simulation, as well as customizing simulations through authoring agent history or creating new base simulations. There are specific directions for generating necessary files, installing requirements, starting servers, and utilizing different commands to interact with the simulations, providing a comprehensive guide for interacting with the generative agents in the game environment of Smallville.

***[Refer to Repository](https://github.com/joonspk-research/generative_agents)***


*Park, O'Brien, Cai, Morris, Liang, Bernstein* <br></br>

---

#### GitHub: [FaceChain](https://github.com/modelscope/facechain)


**Summary:**
FaceChain is a deep-learning toolchain designed to generate a digital twin using a single portrait photo. It enables users to create personal photos in various settings and is powered by ModelScope, offering compatibility with various Python and GPU configurations. Recent updates include resolving a GPU memory issue, adding a depth parameter to git clone to shorten download time, and providing installation guides for Docker, notebooks, and a detailed description of the algorithm's training and inference stages.

***[Refer to Repository](https://github.com/modelscope/facechain)***

---

#### GitHub: [FaceChain](https://github.com/modelscope/facechain)


**Summary:**
FaceChain is a deep-learning toolchain designed to generate a digital twin using a single portrait photo. It enables users to create personal photos in various settings and is powered by ModelScope, offering compatibility with various Python and GPU configurations. Recent updates include resolving a GPU memory issue, adding a depth parameter to git clone to shorten download time, and providing installation guides for Docker, notebooks, and a detailed description of the algorithm's training and inference stages.

***[Refer to Repository](https://github.com/modelscope/facechain)***

---

#### Langchain: [GPT Researcher x LangChain](https://blog.langchain.dev/gpt-researcher-x-langchain/)


**Summary:**
LangChain has integrated with GPT Researcher, a leading open-source research assistant, to enhance web research using Large Language Models (LLMs). The integration provides easy access to various LLM models and facilitates seamless logging with LangSmith, a debugging/logging/monitoring platform. LangChain believes that this collaboration represents a significant opportunity for LLMs and sees it as part of the future, with a focus on complex but targeted applications.

***[Refer to Article](https://blog.langchain.dev/gpt-researcher-x-langchain/)***

---

#### Langchain: [Villagers x LangSmith: Simulating multi-agent social networks with LangSmith](https://blog.langchain.dev/villagers-x-langsmith-simulating-multi-agent-social-networks/)


**Summary:**
The Villagers team collaborated with LangSmith to create a proof-of-concept for simulating multi-agent social networks, particularly mimicking real Twitter users' interactions. By utilizing LangSmith's capabilities, they were able to automate traces, quickly iterate on prompts, and efficiently debug for this complex scenario, including testing community responses to ad campaigns, political statements, and social commentary. The use of LangSmith significantly sped up development time and enhanced the confidence in the quality of the prompts in a system that required managing a large number of agents running in parallel.

***[Refer to Article](https://blog.langchain.dev/villagers-x-langsmith-simulating-multi-agent-social-networks/)***

---

#### Langchain: [NeumAI x LangChain: Efficiently maintaining context in sync for AI applications](https://blog.langchain.dev/neum-x-langchain/)


**Summary:**
NeumAI and LangChain have collaborated to enhance AI applications by maintaining context synchronously and efficiently, especially for data that constantly changes like team documentation. They have introduced scheduling and orchestration to the ingestion pipeline, utilizing LangChain text splitters. Neum automatically synchronizes the source data with the vector store, ensuring up-to-date context, and uses efficient vectorizing technology to reduce costs, all of which can be applied to large-scale AI applications like chatbots to make them more accurate and responsive.

***[Refer to Article](https://blog.langchain.dev/neum-x-langchain/)***


---

### Practical Tutorials and Resources

[Building a RCI Chain for Agents with LangChain Expression Language](https://www.youtube.com/watch?v=QaKM5s0TnsY) - 
***Sam Witteveen*** <br></br>

[LangSmith From LangChain | Building production-grade LLM Apps](https://www.youtube.com/watch?v=M0fmlzbwcbo) - 
***Data Science Basics*** <br></br>

[Now in AI: Handpicked by Better Programming](https://anupamchugh.medium.com/list/now-in-ai-handpicked-by-better-programming-b788e9676cd5) - 
***Various Medium Authors*** <br></br>

[Introducing ModelFusion: Build AI apps with JavaScript and TypeScript](https://dev.to/lgrammel/introducing-modelfusion-build-ai-apps-with-javascript-and-typescript-4aia) - 
***Lars Grammel*** <br></br>




