---
title: "AI Developments: Report #3"
meta_title: "Latest Developments"
description: "Latest developments in the field of AI (Aug 21, 2023 - Aug 28, 2023)"
date: 2023-08-28T04:00:00Z
image: "https://dzslhiqiy3lnx.cloudfront.net/post-3/post-3-main.png"
categories: ["Technology", "Data"]
author: "Johnny Shollaj"
tags: ["AI", "Machine Learning"]
draft: false
---

Another week where we noticed an exponential development in LLMs and more efforts to moderate answers.
Progress has been noted also in multimodal and recommender system development, while more AI startups are
receiving massive hype.

#### How con artists use AI, apps, social engineering to target parents, grandparents for theft

<a href="https://www.cbsnews.com/news/how-con-artists-use-ai-apps-to-steal-60-minutes-transcript/">
  <img src="https://assets3.cbsnewsstatic.com/hub/i/r/2023/05/19/7919cb6f-0c2b-4b74-ba13-bdd35f4c43fb/thumbnail/1240x698/9d17c2b004047f49fb47c0f305b97b75/digital-theft-transcript.jpg?v=85153828b1c3c07a041ab8e73ff87e39" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>



**Main Highlight:** The article discusses the growing problem of online scams targeting older Americans, revealing that seniors are the group losing the most money to these scams. Utilizing AI, social engineering, and readily available apps, scammers are executing increasingly sophisticated operations, including the "grandparent scam," which cost victims thousands of dollars. A report from the FBI notes that Americans lost over $10 billion to online scams and digital fraud last year.

**Terms to Understand:** Grandparent Scam, Social Engineering, Ethical Hacker

***[Read Full Article](https://www.cbsnews.com/news/how-con-artists-use-ai-apps-to-steal-60-minutes-transcript/)***

*Sharyn Alfonsi | CBS News* <br></br>
*Publication Date: August 27, 2023*

---
#### Midjourney Takes on Photoshop with Its Own AI Generative Fill-Like Feature

<a href="https://beebom.com/midjourney-generative-fill-feature-takes-on-photoshop/">
  <img src="https://beebom.com/wp-content/uploads/2023/08/This-image-represents-the-Midjourney-server-on-Discord.jpg?quality=75&strip=all" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>



**Main Highlight:** Midjourney, a leading AI art generator, is launching a new feature called Vary (Region), designed to compete with Adobe Photoshop’s Generative Fill tool. The Vary (Region) feature allows users to regenerate specific parts of an upscaled image, giving them the ability to add, remove, or alter elements within the image.

**Terms to Understand:** Generative Fill, Vary (Region), Text-to-Image Generation

***[Read Full Article](https://beebom.com/midjourney-generative-fill-feature-takes-on-photoshop/)***

*Siddhartha Samaddar | Beebom* <br></br>
*Publication Date: August 27, 2023*

---

#### Can AI-generated art be copyrighted? A US judge says not, but it’s just a matter of time

<a href="https://www.theguardian.com/commentisfree/2023/aug/26/ai-generated-art-copyright-law-recent-entrance-paradise-creativity-machine">
<img src="https://i.guim.co.uk/img/media/85c3866dcc65fd37d2e15aff02fc846204b0b57c/0_0_1890_1417/master/1890.jpg?width=620&dpr=2&s=none" width="500" height="500" alt="Generative AI: Liquid Networks"></img>
</a>

**Main Highlight:** A U.S. federal judge recently denied copyright protection to an artwork generated solely by an AI, citing that current American copyright laws protect only works of human creation. However, the judge acknowledged that copyright law is flexible enough to adapt to technological innovations and suggested that it's just a matter of time before works created by AI could qualify for copyright.

**Terms to Understand:** Human Involvement Criterion, Copyright Law, AI-Generated Art

***[Read Full Article](https://www.theguardian.com/commentisfree/2023/aug/26/ai-generated-art-copyright-law-recent-entrance-paradise-creativity-machine)***

*John Naughton | The Guardian* <br></br>
*Publication Date: August 26, 2023*

---


#### How To Use AI To Create an Award-Winning Podcast

<a href="https://www.entrepreneur.com/growing-a-business/using-chatgpt-and-ai-for-podcast-content-strategy/458084">
<img src="https://media.wired.com/photos/6435f92f13021b2cf16d62ab/16:9/w_2400,h_1350,c_limit/AI-Podcast-GettyImages-1131242410.jpg" width="500" height="500" alt="Open AI: Generative AI Company"></img>
</a>


**Main Highlight:** The article discusses how the integration of AI and predictive analytics can give podcast creators a competitive edge by tailoring content to their audience, automating content curation, enhancing listener interaction, and personalizing advertising. However, it emphasizes the need to maintain the human element for authenticity and personal touch in podcasts.

**Terms to Understand:** Predictive Analytics, Artificial Intelligence (AI), Content Strategy

***[Read Full Article](https://www.entrepreneur.com/growing-a-business/using-chatgpt-and-ai-for-podcast-content-strategy/458084)***

*Entrepreneur | Adam Torkildson* <br></br>
*Publication Date: August 25, 2023*

---

#### Using GPT-4 for content moderation

<a href="https://www.visualcapitalist.com/nvidia-vs-amd-vs-intel-comparing-ai-chip-sales/">
<img src="https://www.visualcapitalist.com/wp-content/uploads/2023/08/Nvidia-vs-AMD-vs-Intel_AI-Chip-Sales.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight:** Nvidia has emerged as a dominant player in AI chip sales, with its Data Center revenue reaching $10.3 billion in Q2 2023 and capturing more than 70% of the AI chip market share. AMD trails behind, but is refocusing on AI with new chips offering more memory. Intel lags significantly, facing declining revenue and nearly no share in the AI chip market.

**Terms to Understand:** Data Center Revenue, Market Share, AI Chips

***[Read Full Article](https://www.visualcapitalist.com/nvidia-vs-amd-vs-intel-comparing-ai-chip-sales/)***

*Visual Capitalist | Jenna Ross & Sam Parker* <br></br>
*Publication Date: August 25, 2023*

---
### Research Blogs

#### Teaching language models to reason algorithmically

<a href="https://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEin8actGxFN2C2mvGMhV_fSzN4Cta1Yd84uvVO5fRO2RcMjzrPY1t-V0mJ2u0x1s0zpCW3bKLX-_3kF4twqNyQMMTrmlTeOvfVdwS6iMYabwgE_RVPe_PFKM6-JBdGS1B8WyMmiVLRalfhD-mN4c-CE4ZXQNhL-Q8pP3q-uy_Xt6i7VkZCGiKqA97AGFnlB/w640-h89/image1.gif" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight:** The article discusses a new approach for teaching Large Language Models (LLMs) algorithmic reasoning capabilities through in-context learning and algorithmic prompting. This enables LLMs to solve more complex arithmetic problems and work effectively on out-of-distribution examples, potentially unlocking greater reasoning capabilities in such models.

**Terms to Understand:** In-Context Learning, Algorithmic Prompting, Out-of-Distribution Generalization

***[Read Full Article](https://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html)***

*Hattie Zhou, Hanie Sedghi - Google Research* <br></br>
*Updated Publication Date: August 8, 2023*

---

#### Responsible AI at Google Research: Perception Fairness

<a href="https://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfN1jwbJve1vMavRMJkmG6JXejOEdb4irf3KcYGnf-_UdciQRy_gXI0D6x9afEZLjCZwb9C0VfyXbvhuckpTonH8ghjgAJ7yDZsc0OlEOznCZlNg_OQxYacKcwDJSMkWPm8Xc_EROheeAsCYFVyYsigqA7Ydfnl9k5rB6erVkYpL7MqBpdeqIJm9H5sani/w640-h144/image1.gif" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight:** Google's Perception Fairness team is actively working on integrating fairness and inclusion into multimodal machine learning systems, including computer vision and generative AI technologies. The team's research spans from addressing system biases to optimizing performance metrics that include fairness, with practical applications influencing Google's products like Search and Google Photos.

**Terms to Understand:** Multimodal Machine Learning, Perception Fairness, AI Principles


***[Read Full Paper](https://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html)***

*Susanna Ricco and Utsav Prabhu,  Google Research* <br></br>
*Publication Date: August 25, 2023*

---

### Research Papers


#### Scaling Laws for Generative Mixed-Modal Language Models

<a href="https://arxiv.org/pdf/2301.03728.pdf">
<img src="https://media.arxiv-vanity.com/render-output/7160109/x17.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**: The study was conducted to explore the scaling properties of mixed-modal generative language models, examining the interaction between different modalities like text, speech, images, and code.

The research, including over 250 experiments with seven modalities and varying model sizes, has identified new mixed-modal scaling laws that capture both individual modalities and their interactions, predicting competition and synergy.

The findings provide insights into the design and training of mixed-modal models, including guidelines for hyperparameter selection, and will likely advance the development of unified models handling multiple modalities simultaneously.


***[Read Full Paper](https://arxiv.org/pdf/2301.03728.pdf)***

*Aghajanyan, Yu, Conneau, Hsu* <br></br>
*Publication Date: 10 Jan , 2023*

---

#### Sigmoid Loss for Language Image Pre-Training

<a href="https://arxiv.org/pdf/2303.15343.pdf">
<img src="https://www.researchgate.net/publication/369556647/figure/fig1/AS:11431281130904544@1679973129344/SigLiT-ImageNet-0-shot-transfer-results-with-different-training-durations-Large-batch_Q320.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**:This new sigmoid loss method performs better, particularly at smaller batch sizes, and allows for further scaling up of the batch size, without requiring additional resources. With this method, the researchers were able to achieve up to 84.5% ImageNet zero-shot accuracy within two days, making it a promising advancement for image-text pre-training.


***[Read Full Paper](https://arxiv.org/pdf/2303.15343.pdf)***

*Zhai, Mustafa, Kolesnikov, Beyer* <br></br>
*Publication Date: 4 May , 2023*

---

#### “Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models

<a href="https://arxiv.org/pdf/2308.03825.pdf">
<img src="https://www.scmagazine.com/_next/image?url=https%3A%2F%2Ffiles.scmagazine.com%2Fwp-content%2Fuploads%2F2023%2F07%2FScreenshot-2023-07-28-at-12.21.15-PM.png&w=1920&q=75" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>



**Main Highlight**:The paper focuses on the misuse of Large Language Models (LLMs) and the emergence of "jailbreak prompts," which are crafted to bypass safeguards and elicit harmful content from LLMs. 

Through an extensive study of 6,387 prompts, it identifies characteristics and major attack strategies of jailbreak prompts, such as prompt injection and privilege escalation. The paper also highlights that current LLMs and safeguards are not adequately defending against these threats, with some jailbreak prompts achieving a 0.99 attack success rate on models like ChatGPT and GPT-4, and stresses the need for stronger defense mechanisms.


***[Read Full Paper](https://arxiv.org/pdf/2308.03825.pdf)***

*Shen, Chen, Backes, Zhang* <br></br>
*Publication Date: 7 Aug , 2023*

---

#### Platypus: Quick, Cheap, and Powerful Refinement of LLMs

<a href="https://arxiv.org/pdf/2308.07317v1.pdf">
<img src="https://raw.githubusercontent.com/arielnlee/Platypus/master/assets/Best_Platty.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:Platypus, a family of fine-tuned and merged Large Language Models (LLMs), has achieved the strongest performance and tops HuggingFace's Open LLM Leaderboard. 

The project introduces Open-Platypus, a curated dataset released to the public, and describes the process of fine-tuning and merging LoRA modules to bring specific domain knowledge to the forefront. 

The 13B Platypus model can be trained on a single A100 GPU in 5 hours with 25k questions, offering strong performance with significantly less data and compute resources than other state-of-the-art LLMs, opening opportunities for more improvements in the field.


***[Read Full Paper](https://arxiv.org/pdf/2308.07317v1.pdf)***

*Lee, Hunter, Ruiz* <br></br>
*Publication Date: 14 Aug , 2023*

---

#### TeCH: Text-guided Reconstruction of Lifelike Clothed Humans

<a href="https://arxiv.org/pdf/2308.08545.pdf">
<img src="https://i.ytimg.com/vi/MNA38AC9U5g/sddefault.jpg" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:TeCH has introduced a new method for reconstructing 3D clothed human figures from a single image, addressing the unsolved challenge of accurately restoring "unseen regions" of the body. The method leverages descriptive text prompts and a personalized Text-to-Image diffusion model to optimize the 3D human's geometry and texture. 

The technology shows promise for various applications in augmented and virtual reality, gaming, and more, but also raises concerns regarding potential misuse for deep-fake avatars and intellectual property issues.


***[Read Full Paper](https://arxiv.org/pdf/2308.08545.pdf)***

*Huang, Yi, Xiu et.al* <br></br>
*Publication Date: 16 Aug , 2023*

---

#### XSTEST: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models

<a href="https://arxiv.org/pdf/2308.01263.pdf">
<img src="https://media.licdn.com/dms/image/D4D22AQHL9eIg5TEFvg/feedshare-shrink_2048_1536/0/1691223790525?e=2147483647&v=beta&t=Wtr3y3gcczS4gGqiF7NjuqwumAXMUZWdxbxDVszwm1M" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:This paper introduces a test suite called XSTEST to identify exaggerated safety behaviors in large language models (LLMs), such as refusing safe requests due to misinterpretation as unsafe. 

Using XSTEST, the authors found that the Llama2 model exhibits substantial exaggerated safety behavior, refusin1g 38% of test prompts and partially refusing another 22%. 

The findings suggest that this behavior is a result of lexical overfitting, making models overly sensitive to certain words, and that OpenAI's GPT-4 is better calibrated in comparison.


***[Read Full Paper](https://arxiv.org/pdf/2308.01263.pdf)***

*Röttger, Kirk, Vidgen, Attanasio, Bianchi et.al* <br></br>
*Publication Date: 2 Aug , 2023*

---
### Development

#### Llama-GPT


<a href="https://github.com/getumbrel/llama-gpt">
<img src="https://camo.githubusercontent.com/8158198b3f4316b97d9a6d13256ad720aabc7c30e55538a7260f5deebd2a2a8b/68747470733a2f2f617070732e756d6272656c2e636f6d2f6170702f6c6c616d612d6770742f62616467652d6c696768742e737667" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**:A self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device.


***[Repository](https://github.com/getumbrel/llama-gpt)***

*Author: GetUmbrel* <br></br>

---

#### Danswer


<a href="https://github.com/danswer-ai/danswer">
<img src="https://raw.githubusercontent.com/danswer-ai/danswer/1fabd9372d66cd54238847197c33f091a724803b/DanswerWithName.png" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: Danswer allows you to ask natural language questions against internal documents and get back reliable answers backed by quotes and references from the source material so that you can always trust what you get back. You can connect to a number of common tools such as Slack, GitHub, Confluence, amongst others.


***[Repository](https://github.com/danswer-ai/danswer)***

*Author: Danswer-AI* <br></br>

---
#### CoDeF: Content Deformation Fields for Temporally Consistent Video Processing


<a href="https://github.com/qiuyu96/CoDeF">
<img src="https://github.com/qiuyu96/CoDeF/raw/main/docs/teaser.gif" width="500" height="500" alt="Open AI: Content Moderator"></img>
</a>


**Main Highlight**: This repo introduces the content deformation field CoDeF, a new video representation comprising a canonical content field for static content and a temporal deformation field for transformations along time. 

The CoDeF system has been designed to lift image algorithms for video processing, enabling image-to-image translation to be adapted for video-to-video translation and keypoint detection for keypoint tracking without training. This approach provides superior cross-frame consistency in processed videos and can track non-rigid objects like water and smog.


***[Repository](https://github.com/qiuyu96/CoDeF)***

*Author: Ouyang, Wang, Xiao, Bai, Zhang, Zhou et.al* <br></br>

---

### Practical Tutorials and Resources

<br></br>

[CS324 - Large Language Models](https://stanford-cs324.github.io/winter2022/lectures/) 

Stanford Course on LLMs - Notes are open-sourced in the given links

***Liang, Hashimoto, Re, Bommasani, Xie | Stanford*** <br></br>

---

[Large Language Models: Foundation Models from the Ground Up](https://learning.edx.org/course/course-v1:Databricks+LLM102x+2T2023/home)

Databricks course available on EDX, starting from ground up to the main elements of Generative AI. Complementary for the LLM specialty certification.

***Zaharia, Raymond, Eng | Databricks*** <br></br>

---

[LangChain: Various Tutorials](https://blog.langchain.dev/)

Various tutorials which integrate LangChain with specific tools or frameworks, such as Predibase, Zep or Qdrant

***LangChain et. al*** <br></br>

---

[DeepLearning AI: Large Language Models with Semantic Search](https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/)

Free tutorial teaching concepts like dense retrieval, which elevates the relevance of retrieved information, leading to improved search results beyond traditional keyword search, and reranking, which injects the intelligence of LLMs into asearch system, making it faster and more effective.  

***Cohere x DeepLearning*** <br></br>

---

[DeepLearning AI: Evaluating and Debugging Generative AI](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)

Free tutorial teaching concepts like monitoring and tracing of LLMs over time in complex interactions and properly debugging by use case.

***W&B x DeepLearning*** <br></br>

---

[DeepLearning AI: Building Generative AI Applications with Gradio](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/)

Free tutorial teaching how to create apps which integrate easily Generative AI (Hugging Face Integrations).

***Hugging Face x DeepLearning*** <br></br>



